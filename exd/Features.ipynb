{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.sql import SQLContext, Row\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shakespeare_RDD = sc.textFile('pg100.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9_ ]', '', text.lower()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'the project gutenberg ebook of the complete works of william shakespeare by'),\n",
       " (1, u'william shakespeare'),\n",
       " (2, u'this ebook is for the use of anyone anywhere at no cost and with'),\n",
       " (3, u'almost no restrictions whatsoever  you may copy it give it away or'),\n",
       " (4, u'reuse it under the terms of the project gutenberg license included'),\n",
       " (5, u'with this ebook or online at wwwgutenbergorg'),\n",
       " (6, u'this is a copyrighted project gutenberg ebook details below'),\n",
       " (7, u'please follow the copyright guidelines in this file'),\n",
       " (8, u'title the complete works of william shakespeare'),\n",
       " (9, u'author william shakespeare')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_pair = shakespeare_RDD.filter(lambda l: l!=\"\").zipWithIndex().map(lambda (l, num): (num, remove_punctuation(l)))\n",
    "shakespeare_pair.take(10)\n",
    "# shakespeare = sqlContext.createDataFrame(shakespeare_pair, [\"label\", \"sentence\"])\n",
    "# shakespeare.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(features=SparseVector(20, {1: 1.4962, 3: 1.8524, 5: 0.8358, 6: 1.4844, 9: 1.6455, 11: 1.1623, 14: 1.186, 15: 1.3522, 18: 1.5727, 19: 1.0818}), label=0)\n",
      "Row(features=SparseVector(20, {11: 1.1623, 14: 1.186}), label=1)\n",
      "Row(features=SparseVector(20, {1: 2.2443, 3: 2.7786, 7: 1.3045, 10: 2.066, 14: 2.372, 17: 0.9354, 18: 1.5727}), label=2)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(shakespeare)\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "for features_label in rescaledData.select(\"features\", \"label\").take(3):\n",
    "  print(features_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([u'the',\n",
       "   u'project',\n",
       "   u'gutenberg',\n",
       "   u'ebook',\n",
       "   u'of',\n",
       "   u'the',\n",
       "   u'complete',\n",
       "   u'works',\n",
       "   u'of',\n",
       "   u'william',\n",
       "   u'shakespeare',\n",
       "   u'by'],),\n",
       " ([u'william', u'shakespeare'],),\n",
       " ([u'this',\n",
       "   u'ebook',\n",
       "   u'is',\n",
       "   u'for',\n",
       "   u'the',\n",
       "   u'use',\n",
       "   u'of',\n",
       "   u'anyone',\n",
       "   u'anywhere',\n",
       "   u'at',\n",
       "   u'no',\n",
       "   u'cost',\n",
       "   u'and',\n",
       "   u'with'],)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_text = shakespeare_RDD.filter(lambda l: l!=\"\").map(lambda l: (remove_punctuation(l).split(' '),))\n",
    "shakespeare_text.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(result=DenseVector([-0.2539, -0.8469, 1.5684]))\n",
      "Row(result=DenseVector([-0.2704, -1.4223, 2.4582]))\n",
      "Row(result=DenseVector([0.1871, -0.043, 0.1224]))\n"
     ]
    }
   ],
   "source": [
    "sentenceDataFrame = sqlContext.createDataFrame(shakespeare_text, [\"text\"])\n",
    "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"text\", outputCol=\"result\")\n",
    "model = word2Vec.fit(sentenceDataFrame)\n",
    "result = model.transform(sentenceDataFrame)\n",
    "for feature in result.select(\"result\").take(3):\n",
    "  print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(words=[u'the', u'project', u'gutenberg', u'ebook', u'of', u'the', u'complete', u'works', u'of', u'william', u'shakespeare', u'by'], label=0)\n",
      "Row(words=[u'william', u'shakespeare'], label=1)\n",
      "Row(words=[u'this', u'ebook', u'is', u'for', u'the', u'use', u'of', u'anyone', u'anywhere', u'at', u'no', u'cost', u'and', u'with'], label=2)\n"
     ]
    }
   ],
   "source": [
    "sentenceDataFrame = sqlContext.createDataFrame(shakespeare_pair, [\"label\", \"sentence\"])\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "wordsDataFrame = tokenizer.transform(sentenceDataFrame)\n",
    "for words_label in wordsDataFrame.select(\"words\", \"label\").take(3):\n",
    "  print(words_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
